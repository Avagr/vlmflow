defaults:
    - _self_
    - task: whatsup
    - model: llava
    - sampling_params: short

prompt: "${model}_${task}_${task.eval_method}"

name: "${model.name}_${v}"
wandb_project: vlmflow
wandb_entity: avagr
v: ???
seed: 57
device: cuda:0

num_workers: 6
pin_memory: true
batch_size: 1

need_grad: false

mixed_precision: false
use_tf32: false

disable_wandb: true
show_tqdm: true
resume_wandb_id: null
detect_anomalies: false
log_samples: 50
results_path: /home/projects/shimon/agroskin/projects/vlmflow/results

model_size: ???

save_full_graphs: true
head_batch_size: 4
renormalization_threshold: null
sparsification_threshold: null

last_token_logit_lens: false
normalize_lens: true